# Waveform-Generator
https://colab.research.google.com/drive/14oGwtsebm6QyyWYwGpfsrUrTa81sH7jL#scrollTo=g2wMkoFeXVmt

---
<img width="1469" alt="Screenshot 2025-05-10 at 12 47 38 AM" src="https://github.com/user-attachments/assets/90ef2509-8aca-424f-a7f6-d9f8301f673f" />
<img width="1467" alt="Screenshot 2025-05-10 at 12 48 01 AM" src="https://github.com/user-attachments/assets/c0209e74-d8a2-45da-b7b6-da5103e74b8b" />
<img width="1470" alt="Screenshot 2025-05-10 at 12 48 20 AM" src="https://github.com/user-attachments/assets/3ea5fd83-4a11-44dc-be76-7e6c25fbb6a4" />

---

**DESCRIPTION**

The aim of the project is to compare and evaluate the performance of various machine
learning models in classifying waveform generator. A multi-feature dataset of waveform
signals was considered. The compared models are Logistic Regression, Random Forest,
Support Vector Machine, Gradient Boosting (XGBoost), and K-Nearest Neighbors.Performance was observed based on accuracy and precision measurements, confusion
matrices, and classification reports.

---

**Data Source**

https://www.kaggle.com/datasets/annsanababy/waveform-dataset?select=waveform.data

---

**Workflow**

1. Data Loading
2. Data Preprocessing
3. Model Selection (User-driven)
4. Model Training & Evaluation
5. Visualization

---

**Tech Stack**

1.Streamlit – For building the interactive web application interface

2.Programming language - Python 

3.Data Handling & Preprocessing: Pandas, NumPy, scikit-learn (sklearn) 

4.Machine Learning Models: scikit-learn – Logistic Regression, SVM, K-Nearest Neighbors, Random Forest, XGBoost – Extreme Gradient Boosting classifier

5.Visualization: Matplotlib, Seaborn 

6.Model Deployment: Streamlit Cloud

